{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "D3RCe4TomwSU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setup some variables for pathes"
      ]
    },
    {
      "metadata": {
        "id": "F7AbWF97mzvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/gdrive/My\\ Drive/porto-dataset-2'\n",
        "TEST_PATH = DATASET_PATH + '/object_detection/images/test'\n",
        "TRAIN_PATH = DATASET_PATH + '/object_detection/images/train'\n",
        "TRAINING_PATH = '/root/training'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6KWFVcpBk75s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Connect to Google Drive\n",
        "The Porto dataset should be stored in Google Drive.\n",
        "\n",
        "As such we need to access it."
      ]
    },
    {
      "metadata": {
        "id": "5wTGDQ-kk8Z2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls '/content/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4NVOaFbkoLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import code from Tensorflow object detection API"
      ]
    },
    {
      "metadata": {
        "id": "QFOaAGKUkt7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p $DATASET_PATH\n",
        "%cd $DATASET_PATH\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "!mv models/research/object_detection $DATASET_PATH\n",
        "!mv -u models/research/slim/* $DATASET_PATH\n",
        "!mv models/research/setup.py $DATASET_PATH\n",
        "!mv object_detection/legacy/train.py .\n",
        "!rm -r models\n",
        "!python setup.py install\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6K5kYkI6ZSbv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Faster-RCNN-Inception-V2 model"
      ]
    },
    {
      "metadata": {
        "id": "7DdMp8mqZVW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "!curl -LO http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
        "\n",
        "!tar -xvf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W1_bvFhnMfVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Import ssd_mobilenet_v1_coco\n",
        "An alternative network could be used."
      ]
    },
    {
      "metadata": {
        "id": "___kW_EvMfAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "!curl -LO http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n",
        "\n",
        "!tar -xvf ssd_mobilenet_v1_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NmP_7J4cElOL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "Create a duplicate of the dataset\n",
        "\n",
        "And create the train and test folder"
      ]
    },
    {
      "metadata": {
        "id": "GA41amlj3oHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "!cp -r '/content/gdrive/My Drive/porto-dataset/resized_dataset.zip' $DATASET_PATH\n",
        "!unzip {DATASET_PATH + '/resized_dataset.zip'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_10lfw8moSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p $TEST_PATH\n",
        "!mkdir -p $TRAIN_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tGALB90eDwiM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Move images\n",
        "Move the first 20% of each category to test"
      ]
    },
    {
      "metadata": {
        "id": "x4cMSDvkTatz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd {DATASET_PATH + '/resized_dataset/images/'}\n",
        "%cd arrabida\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../camara\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../clerigos\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../musica\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../serralves\n",
        "!mv `ls | head -120` $TEST_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPzs-8EFEURd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Move all the other images to train"
      ]
    },
    {
      "metadata": {
        "id": "Hb7UJzbwEMAN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd {DATASET_PATH + '/resized_dataset/'}\n",
        "!mv images/arrabida/*.* $TRAIN_PATH\n",
        "!mv images/camara/*.* $TRAIN_PATH\n",
        "!mv images/clerigos/*.* $TRAIN_PATH\n",
        "!mv images/musica/*.* $TRAIN_PATH\n",
        "!mv images/serralves/*.* $TRAIN_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gwJv0PfU2i8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Move annotations\n",
        "Move the first 20% to test"
      ]
    },
    {
      "metadata": {
        "id": "cr52tLWeU4Z8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd {DATASET_PATH + '/resized_dataset/annotations'}\n",
        "%cd arrabida\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../camara\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../clerigos\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../musica\n",
        "!mv `ls | head -120` $TEST_PATH\n",
        "%cd ../serralves\n",
        "!mv `ls | head -120` $TEST_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7an0iJyRYSSP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Move the other annotations to train"
      ]
    },
    {
      "metadata": {
        "id": "_LzZn8-1W8br",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "!mv resized_dataset/annotations/arrabida/*.* $TRAIN_PATH\n",
        "!mv resized_dataset/annotations/camara/*.* $TRAIN_PATH\n",
        "!mv resized_dataset/annotations/clerigos/*.* $TRAIN_PATH\n",
        "!mv resized_dataset/annotations/musica/*.* $TRAIN_PATH\n",
        "!mv resized_dataset/annotations/serralves/*.* $TRAIN_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pZKGXc6aYKkn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remove unused directories"
      ]
    },
    {
      "metadata": {
        "id": "eWJUIc_wX4fE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "!rm -r resized_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3h7xJiCJv-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convert Dataset\n",
        "After getting the files of the dataset, we need to adapt it to our algorithm.\n",
        "## Import repo for needed files\n",
        "As the repository is private, the files needed should be manualy placed in the drive at the root of the dataset. In this case, to `/content/gdrive/My Drive/porto-dataset-2/object_detection/`."
      ]
    },
    {
      "metadata": {
        "id": "gjjFf1jExr0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "%cd {DATASET_PATH + '/object_detection'}\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKg-upgMDDde",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Label Map"
      ]
    },
    {
      "metadata": {
        "id": "P7Y3X4p5DDO-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p $TRAINING_PATH\n",
        "%cd $TRAINING_PATH\n",
        "!echo \"item {id: 1 name: 'arrabida'}\" > labelmap.pbtxt\n",
        "!echo \"item {id: 2 name: 'camara'}\" >> labelmap.pbtxt\n",
        "!echo \"item {id: 3 name: 'clerigos'}\" >> labelmap.pbtxt\n",
        "!echo \"item {id: 4 name: 'musica'}\" >> labelmap.pbtxt\n",
        "!echo \"item {id: 5 name: 'serralves'}\" >> labelmap.pbtxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JzG4FFsTGFx2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate tensorflow records\n",
        "The TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data."
      ]
    },
    {
      "metadata": {
        "id": "zEwYpb_NGGQ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "\n",
        "!python generate_tfrecord.py \\\n",
        "        --annotations_dir=$TRAIN_PATH \\\n",
        "        --label_map_path='/root/training/labelmap.pbtxt' \\\n",
        "        --output_path='object_detection/train.record'\n",
        "\n",
        "!python generate_tfrecord.py \\\n",
        "        --annotations_dir=$TEST_PATH \\\n",
        "        --label_map_path='/root/training/labelmap.pbtxt' \\\n",
        "        --output_path='object_detection/test.record'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OQ4drIEywbXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network Configuration\n",
        "In addition to the `labelmap`, the `configuration of the network` should also be placed manualy in `/root/training`."
      ]
    },
    {
      "metadata": {
        "id": "L2uEwqebxjot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "%cd $TRAINING_PATH\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "blActWfKuh6m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorboard\n",
        "This allows the user to see the evolution of the training."
      ]
    },
    {
      "metadata": {
        "id": "kykARlC1bJ1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd ~\n",
        "!git clone https://github.com/mixuala/colab_utils\n",
        "\n",
        "import os\n",
        "import colab_utils.tboard\n",
        "\n",
        "ROOT = %pwd\n",
        "\n",
        "colab_utils.tboard.launch_tensorboard(bin_dir=ROOT, log_dir=TRAINING_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lS9cLIJ1zZPw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "C9R1XYW8zXmZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "!python train.py \\\n",
        "  --logtostderr \\\n",
        "  --train_dir=$TRAINING_PATH \\\n",
        "  --pipeline_config_path={TRAINING_PATH + '/faster_rcnn_inception_v2_porto.config'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8yKF7A9aKJJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save model to the drive\n",
        "The training must be on root in order to use tensorboard.\n",
        "After training, the checkpoint should be saved in the drive for future use."
      ]
    },
    {
      "metadata": {
        "id": "LiBQpXlXaJip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r $TRAINING_PATH $DATASET_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PB6hqefBsesD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# See the results\n",
        "## Export inference graph\n",
        "The flag `--trained_checkpoint_prefix` should be changed to the newest checkpoint.\n",
        "\n",
        "The frozen inference graph will be saved to the path of the `output_directory` flag."
      ]
    },
    {
      "metadata": {
        "id": "GVevkv_krILF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd $DATASET_PATH\n",
        "!rm export_inference_graph.py\n",
        "!cp object_detection/export_inference_graph.py .\n",
        "!mkdir -p object_detection/inference_graph\n",
        "!python export_inference_graph.py \\\n",
        "  --input_type image_tensor \\\n",
        "  --pipeline_config_path {TRAINING_PATH + '/faster_rcnn_inception_v2_porto.config'} \\\n",
        "  --trained_checkpoint_prefix {DATASET_PATH + '/training/model.ckpt-3966'} \\\n",
        "  --output_directory object_detection/inference_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUtibIljkPIO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test on Colab"
      ]
    },
    {
      "metadata": {
        "id": "Y2KdQyK_kOK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "PATH_TO_FROZEN_GRAPH = '/content/gdrive/My Drive/porto-dataset-2/object_detection/inference_graph/frozen_inference_graph.pb'\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2wa6agUlkUp7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS = os.path.join(TRAINING_PATH, 'labelmap.pbtxt')\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ri8kNcLZkWOp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TQDSTVXpkYiz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = '/content/gdrive/My Drive/porto-dataset-2/object_detection/images/test'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'arrabida-000{}.jpg'.format(i)) for i in range(1, 3) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (20, 15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bMmd8NF4kagk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "avS85N6OkcYx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}